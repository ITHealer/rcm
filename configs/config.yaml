# # ============================================================================
# # MAIN CONFIGURATION
# # ============================================================================
# # Complete configuration for recommendation system
# # Merged from offline, online, and redis configs

# # ============================================================================
# # SYSTEM
# # ============================================================================
# system:
#   name: "recommendation-system"
#   version: "1.0.0"
#   environment: "development"  # development, staging, production
#   log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR

# # ============================================================================
# # DATA
# # ============================================================================
# data:
#   # Data source
#   source: "csv"  # csv or database
#   dir: "dataset"
  
#   # CSV files
#   csv_files:
#     users: "User.csv"
#     posts: "Post.csv"
#     reactions: "PostReaction.csv"
#     friendships: "Friendship.csv"
  
#   # Database (if source = "database")
#   database:
#     host: "localhost"
#     port: 5432
#     database: "social_network"
#     user: "postgres"
#     password: "password"
  
#   # Data processing
#   lookback_days: 90
#   chunk_size: 100000
  
#   # Train/test split
#   train_test_split:
#     test_days: 7
#     val_days: 7

# # ============================================================================
# # TIME DECAY
# # ============================================================================
# time_decay:
#   enabled: true
#   half_life_days: 7.0  # Interactions lose 50% weight after 7 days
#   min_weight: 0.01     # Minimum weight (1% of original)

# # ============================================================================
# # EMBEDDINGS
# # ============================================================================
# embeddings:
#   model_name: "sentence-transformers/all-MiniLM-L6-v2"
#   embedding_dim: 384
#   batch_size: 512
#   normalize: true
#   device: "auto"  # auto, cuda, cpu

# # ============================================================================
# # COLLABORATIVE FILTERING
# # ============================================================================
# collaborative_filtering:
#   min_interactions: 5
#   top_k_similar: 50
#   similarity_metric: "cosine"

# # ============================================================================
# # RANKING MODEL
# # ============================================================================
# ranking_model:
#   algorithm: "lightgbm"
  
#   # LightGBM hyperparameters
#   params:
#     boosting_type: "gbdt"
#     objective: "binary"
#     metric: "auc"
#     num_leaves: 31
#     max_depth: 6
#     learning_rate: 0.05
#     feature_fraction: 0.8
#     bagging_fraction: 0.8
#     bagging_freq: 5
#     lambda_l1: 0.1
#     lambda_l2: 0.1
#     min_data_in_leaf: 20
#     verbose: -1
#     n_jobs: -1
#     seed: 42
  
#   # Training
#   num_boost_round: 1000
#   early_stopping_rounds: 50

# # ============================================================================
# # FEATURES
# # ============================================================================
# features:
#   # Feature categories
#   user_features: 15
#   post_features: 18
#   author_features: 7
#   interaction_features: 7
#   total_features: 47

# # ============================================================================
# # ONLINE INFERENCE
# # ============================================================================
# online:
#   # Recall
#   recall:
#     target_count: 1000
#     channels:
#       following:
#         enabled: true
#         count: 400
#         weight: 0.40
      
#       collaborative_filtering:
#         enabled: true
#         count: 300
#         weight: 0.30
      
#       content_based:
#         enabled: true
#         count: 200
#         weight: 0.20
      
#       trending:
#         enabled: true
#         count: 100
#         weight: 0.10
  
#   # Ranking
#   ranking:
#     top_k: 100
#     use_scaler: true
  
#   # Re-ranking
#   reranking:
#     diversity:
#       enabled: true
#       max_same_author: 2
    
#     freshness:
#       enabled: true
#       boost_hours: 24
#       boost_factor: 1.5
    
#     quality:
#       enabled: true
#       min_engagement: 0.01
  
#   # Final output
#   output:
#     limit: 50
#     min_score: 0.0

# # ============================================================================
# # REDIS
# # ============================================================================
# redis:
#   host: "localhost"
#   port: 6380
#   db: 0
#   password: null
  
#   # Connection pool
#   max_connections: 50
  
#   # TTL (seconds)
#   ttl:
#     embedding_user: 604800      # 7 days
#     embedding_post: 2592000     # 30 days
#     cf_similarity: 604800       # 7 days
#     user_stats: 86400           # 24 hours
#     author_stats: 86400         # 24 hours
#     following_feed: 172800      # 48 hours
#     trending_1h: 3600           # 1 hour
#     trending_6h: 21600          # 6 hours
#     trending_24h: 86400         # 24 hours
#     user_interactions: 2592000  # 30 days

# # ============================================================================
# # API
# # ============================================================================
# api:
#   host: "0.0.0.0"
#   port: 8000
#   workers: 4
#   reload: false
  
#   # CORS
#   cors:
#     enabled: true
#     origins:
#       - "http://localhost:3000"
#       - "http://localhost:8080"
  
#   # Rate limiting
#   rate_limit:
#     enabled: true
#     requests_per_minute: 60

# # ============================================================================
# # MODELS & ARTIFACTS
# # ============================================================================
# models:
#   dir: "models"
#   keep_last_n_versions: 5
  
#   # Artifacts to save
#   artifacts:
#     - "embeddings.pkl"
#     - "faiss_index.bin"
#     - "faiss_post_ids.pkl"
#     - "cf_model.pkl"
#     - "ranking_model.txt"
#     - "ranking_scaler.pkl"
#     - "ranking_feature_cols.pkl"
#     - "user_stats.pkl"
#     - "author_stats.pkl"
#     - "following_dict.pkl"
#     - "metadata.json"

# # ============================================================================
# # BATCH JOBS
# # ============================================================================
# batch_jobs:
#   # Post embeddings (every 6 hours)
#   post_embeddings:
#     enabled: true
#     schedule: "0 */6 * * *"  # Cron: 00:00, 06:00, 12:00, 18:00
#     lookback_hours: 6
  
#   # Full retraining (weekly)
#   full_training:
#     enabled: true
#     schedule: "0 2 * * 0"  # Cron: Sunday 2 AM
  
#   # Trending update (every 15 min)
#   trending_update:
#     enabled: true
#     schedule: "*/15 * * * *"

# # ============================================================================
# # LOGGING
# # ============================================================================
# logging:
#   dir: "logs"
  
#   files:
#     offline: "offline_training.log"
#     online: "online_inference.log"
#     cache: "cache_updates.log"
#     api: "api.log"
  
#   format: "[%(asctime)s] %(levelname)s - %(name)s - %(message)s"
#   date_format: "%Y-%m-%d %H:%M:%S"

# # ============================================================================
# # MONITORING
# # ============================================================================
# monitoring:
#   enabled: true
  
#   # Metrics to track
#   metrics:
#     - "request_latency"
#     - "cache_hit_rate"
#     - "model_accuracy"
#     - "throughput"
  
#   # Alerting
#   alerts:
#     latency_threshold_ms: 200
#     error_rate_threshold: 0.05
#     cache_hit_rate_threshold: 0.90

# # ============================================================================
# # PERFORMANCE
# # ============================================================================
# performance:
#   # Latency targets (milliseconds)
#   latency_targets:
#     recall: 50
#     feature_extraction: 60
#     ranking: 30
#     reranking: 10
#     total: 200
  
#   # Throughput targets
#   throughput_target: 100  # requests per second
  
#   # Cache hit rate target
#   cache_hit_rate_target: 0.95

# # ============================================================================
# # DOCKER
# # ============================================================================
# docker:
#   registry: "localhost:5000"
  
#   images:
#     offline: "recommendation-offline:latest"
#     online: "recommendation-online:latest"
  
#   replicas:
#     online_api: 4


# ============================================================================
# MAIN CONFIGURATION FILE
# ============================================================================
# Complete configuration for recommendation system

system:
  name: "social-recommendation-system"
  version: "1.0.0"
  environment: "development"  # development, staging, production
  log_level: "INFO"

# ============================================================================
# DATA CONFIGURATION
# ============================================================================
data:
  source: "csv"  # csv or database
  dir: "dataset"
  
  csv_files:
    users: "User.csv"
    posts: "Post.csv"
    reactions: "PostReaction.csv"
    friendships: "Friendship.csv"
  
  database:
    host: "localhost"
    port: 5432
    database: "social_network"
    user: "postgres"
    password: "${DB_PASSWORD}"
  
  lookback_days: 14
  chunk_size: 100000

# ============================================================================
# TIME DECAY CONFIGURATION
# ============================================================================
time_decay:
  enabled: true
  half_life_days: 7.0
  min_weight: 0.01
  
  action_multipliers:
    view: 0.5
    like: 1.0
    comment: 1.5
    share: 2.0
    save: 1.2
    hide: -3.0
    report: -5.0

# ============================================================================
# EMBEDDINGS CONFIGURATION
# ============================================================================
embeddings:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  embedding_dim: 384
  batch_size: 512
  normalize: true
  device: "auto"

# ============================================================================
# COLLABORATIVE FILTERING
# ============================================================================
collaborative_filtering:
  min_interactions: 5
  top_k_similar_users: 50
  top_k_similar_items: 50
  similarity_metric: "cosine"

# ============================================================================
# RANKING MODEL (LightGBM)
# ============================================================================
ranking_model:
  algorithm: "lightgbm"
  
  params:
    boosting_type: "gbdt"
    objective: "binary"
    metric: "auc"
    num_leaves: 31
    max_depth: 6
    learning_rate: 0.05
    feature_fraction: 0.8
    bagging_fraction: 0.8
    bagging_freq: 5
    lambda_l1: 0.1
    lambda_l2: 0.1
    min_data_in_leaf: 20
    verbose: -1
    n_jobs: -1
    seed: 42
  
  num_boost_round: 1000
  early_stopping_rounds: 50

# ============================================================================
# ONLINE INFERENCE CONFIGURATION
# ============================================================================
online:
  # Multi-channel recall
  recall:
    target_count: 1000
    
    channels:
      following:
        enabled: true
        count: 400
        weight: 0.40
        recent_hours: 48
      
      collaborative_filtering:
        enabled: true
        count: 300
        weight: 0.30
      
      content_based:
        enabled: true
        count: 200
        weight: 0.20
      
      trending:
        enabled: true
        count: 100
        weight: 0.10
        recent_hours: 6
  
  # Ranking
  ranking:
    top_k: 100
    use_scaler: true
  
  # Re-ranking & Business rules
  reranking:
    diversity:
      enabled: true
      max_consecutive_same_author: 2
      max_same_author_in_feed: 5
    
    freshness:
      enabled: true
      boost_hours: 24
      boost_factor: 1.5
    
    quality:
      enabled: true
      min_score: 0.3
  
  # Performance
  latency:
    target_ms: 200
    timeout_ms: 500

# ============================================================================
# REDIS CONFIGURATION
# ============================================================================
redis:
  host: "localhost"
  port: 6380
  db: 0
  password: null
  max_connections: 50
  socket_timeout: 5
  socket_connect_timeout: 2
  
  ttl:
    user_embedding: 604800      # 7 days
    post_embedding: 2592000      # 30 days
    cf_similarity: 86400         # 1 day
    user_stats: 86400            # 1 day
    author_stats: 86400          # 1 day
    following: 3600              # 1 hour
    trending: 300                # 5 minutes

# ============================================================================
# OFFLINE TRAINING CONFIGURATION
# ============================================================================
offline:
  schedule:
    frequency: "weekly"  # daily, weekly
    day_of_week: "sunday"
    time: "02:00"
  
  training:
    train_test_split:
      test_days: 7
      val_days: 7
    
    sample_negative_ratio: 5
    
  artifacts:
    base_dir: "models"
    keep_versions: 5

# ============================================================================
# API CONFIGURATION
# ============================================================================
api:
  host: "0.0.0.0"
  port: 8010
  workers: 4
  reload: false
  
  cors:
    enabled: true
    origins: ["*"]
  
  rate_limiting:
    enabled: true
    requests_per_minute: 60

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================
logging:
  level: "INFO"
  format: "[%(asctime)s] %(levelname)s - %(name)s - %(message)s"
  file: "logs/recommendation.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5

# ============================================================================
# MONITORING
# ============================================================================
monitoring:
  enabled: true
  metrics:
    - "latency"
    - "recall_count"
    - "ranking_score_distribution"
    - "diversity_score"
  
  alerts:
    latency_threshold_ms: 300
    error_rate_threshold: 0.05